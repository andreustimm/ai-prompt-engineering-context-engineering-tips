"""
Prompt Chaining (Encadeamento de Prompts)

T√©cnica que conecta m√∫ltiplos prompts em um pipeline, onde a sa√≠da
de um prompt se torna a entrada para o pr√≥ximo, criando um fluxo de trabalho.

Casos de uso:
- Pipelines de cria√ß√£o de conte√∫do
- Fluxos de pesquisa e an√°lise
- Cadeias de processamento de dados
- Gera√ß√£o de documentos em m√∫ltiplas etapas
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from langchain_core.prompts import ChatPromptTemplate
from config import (
    get_llm,
    TokenUsage,
    extract_tokens_from_response,
    print_token_usage,
    print_total_usage
)

# Rastreador global de tokens para este script
token_tracker = TokenUsage()


def executar_passo_cadeia(prompt_template: ChatPromptTemplate, inputs: dict, nome_passo: str, temperature: float = 0.7) -> str:
    """Executa um √∫nico passo na cadeia de prompts."""
    llm = get_llm(temperature=temperature)
    chain = prompt_template | llm
    response = chain.invoke(inputs)

    # Extrai e registra tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, nome_passo)

    return response.content


def pesquisar_analisar_resumir(topico: str) -> dict:
    """
    Uma cadeia de tr√™s passos: Pesquisar -> Analisar -> Resumir

    Passo 1: Reunir fatos principais sobre o t√≥pico
    Passo 2: Analisar implica√ß√µes e conex√µes
    Passo 3: Criar um resumo executivo
    """
    resultados = {}

    # Passo 1: Pesquisar
    print("\n   Passo 1: Pesquisando t√≥pico...")
    prompt_pesquisa = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em pesquisa. Re√∫na e liste fatos principais sobre o t√≥pico dado.
Inclua: defini√ß√µes, estat√≠sticas principais, principais atores/componentes, contexto hist√≥rico e estado atual.
Formate como pontos organizados."""),
        ("user", "T√≥pico de pesquisa: {topico}")
    ])

    resultados["pesquisa"] = executar_passo_cadeia(
        prompt_pesquisa, {"topico": topico}, "Pesquisa", temperature=0.3
    )

    # Passo 2: Analisar
    print("\n   Passo 2: Analisando descobertas...")
    prompt_analise = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista anal√≠tico. Baseado nas descobertas da pesquisa fornecidas,
identifique padr√µes, implica√ß√µes, oportunidades e desafios potenciais.
Forne√ßa insights profundos que v√£o al√©m dos fatos superficiais."""),
        ("user", """Descobertas da pesquisa:
{pesquisa}

Forne√ßa sua an√°lise:""")
    ])

    resultados["analise"] = executar_passo_cadeia(
        prompt_analise, {"pesquisa": resultados["pesquisa"]}, "An√°lise", temperature=0.5
    )

    # Passo 3: Resumir
    print("\n   Passo 3: Criando resumo executivo...")
    prompt_resumo = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em comunica√ß√£o empresarial. Crie um resumo executivo conciso
que combine a pesquisa e an√°lise em insights acion√°veis.
Mantenha em menos de 200 palavras cobrindo os pontos mais importantes."""),
        ("user", """Pesquisa:
{pesquisa}

An√°lise:
{analise}

Crie o resumo executivo:""")
    ])

    resultados["resumo"] = executar_passo_cadeia(
        prompt_resumo,
        {"pesquisa": resultados["pesquisa"], "analise": resultados["analise"]},
        "Resumo",
        temperature=0.4
    )

    return resultados


def pipeline_criacao_conteudo(topico: str, publico_alvo: str, tipo_conteudo: str = "artigo de blog") -> dict:
    """
    Pipeline de cria√ß√£o de conte√∫do: Esbo√ßo -> Rascunho -> Edi√ß√£o -> Polimento

    Passo 1: Criar esbo√ßo detalhado
    Passo 2: Escrever primeiro rascunho
    Passo 3: Editar para clareza e fluidez
    Passo 4: Polir e finalizar
    """
    resultados = {}

    # Passo 1: Esbo√ßo
    print("\n   Passo 1: Criando esbo√ßo...")
    prompt_esboco = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um estrategista de conte√∫do. Crie um esbo√ßo detalhado para um {tipo_conteudo}
sobre o t√≥pico dado, otimizado para o p√∫blico-alvo.
Inclua: gancho/intro, se√ß√µes principais, pontos-chave para cada se√ß√£o e conclus√£o."""),
        ("user", """T√≥pico: {topico}
P√∫blico-alvo: {publico}

Crie o esbo√ßo:""")
    ])

    resultados["esboco"] = executar_passo_cadeia(
        prompt_esboco,
        {"topico": topico, "publico": publico_alvo, "tipo_conteudo": tipo_conteudo},
        "Esbo√ßo",
        temperature=0.5
    )

    # Passo 2: Rascunho
    print("\n   Passo 2: Escrevendo primeiro rascunho...")
    prompt_rascunho = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um escritor de conte√∫do habilidoso. Escreva o primeiro rascunho baseado no esbo√ßo fornecido.
Foque em colocar todas as ideias com boa fluidez, mas n√£o se preocupe com perfei√ß√£o ainda.
Escreva em um estilo apropriado para um {tipo_conteudo}."""),
        ("user", """Esbo√ßo:
{esboco}

P√∫blico-alvo: {publico}

Escreva o primeiro rascunho:""")
    ])

    resultados["rascunho"] = executar_passo_cadeia(
        prompt_rascunho,
        {"esboco": resultados["esboco"], "publico": publico_alvo, "tipo_conteudo": tipo_conteudo},
        "Rascunho",
        temperature=0.7
    )

    # Passo 3: Edi√ß√£o
    print("\n   Passo 3: Editando para clareza...")
    prompt_edicao = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um editor profissional. Revise e edite o rascunho para:
- Clareza e legibilidade
- Fluxo l√≥gico entre par√°grafos
- Remo√ß√£o de redund√¢ncias
- Escolhas de palavras mais fortes
- Tom consistente

Forne√ßa a vers√£o editada."""),
        ("user", """Rascunho para editar:
{rascunho}

P√∫blico-alvo: {publico}

Vers√£o editada:""")
    ])

    resultados["editado"] = executar_passo_cadeia(
        prompt_edicao,
        {"rascunho": resultados["rascunho"], "publico": publico_alvo},
        "Edi√ß√£o",
        temperature=0.3
    )

    # Passo 4: Polimento
    print("\n   Passo 4: Polimento final...")
    prompt_polimento = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em publica√ß√£o. Aplique o polimento final ao conte√∫do:
- Garanta gram√°tica e pontua√ß√£o perfeitas
- Adicione abertura e fechamento envolventes
- Otimize para engajamento
- Adicione transi√ß√µes que estejam faltando
- Garanta que est√° pronto para publica√ß√£o

Forne√ßa a vers√£o final polida."""),
        ("user", """Conte√∫do para polir:
{editado}

Vers√£o final polida:""")
    ])

    resultados["final"] = executar_passo_cadeia(
        prompt_polimento,
        {"editado": resultados["editado"]},
        "Polimento",
        temperature=0.3
    )

    return resultados


def cadeia_insight_dados(descricao_dados: str, contexto_negocio: str) -> dict:
    """
    Cadeia de an√°lise de dados: Extrair -> Interpretar -> Recomendar

    Passo 1: Extrair pontos de dados principais
    Passo 2: Interpretar padr√µes e tend√™ncias
    Passo 3: Gerar recomenda√ß√µes de neg√≥cio
    """
    resultados = {}

    # Passo 1: Extrair
    print("\n   Passo 1: Extraindo pontos de dados principais...")
    prompt_extracao = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um analista de dados. Da descri√ß√£o de dados fornecida,
identifique e liste as m√©tricas principais, tend√™ncias e pontos de dados not√°veis.
Seja espec√≠fico com n√∫meros e porcentagens onde dispon√≠vel."""),
        ("user", """Descri√ß√£o dos dados:
{dados}

Contexto de neg√≥cio: {contexto}

Extraia os pontos de dados principais:""")
    ])

    resultados["extracao"] = executar_passo_cadeia(
        prompt_extracao,
        {"dados": descricao_dados, "contexto": contexto_negocio},
        "Extra√ß√£o",
        temperature=0.2
    )

    # Passo 2: Interpretar
    print("\n   Passo 2: Interpretando padr√µes...")
    prompt_interpretacao = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em intelig√™ncia de neg√≥cios. Baseado nos pontos de dados extra√≠dos,
identifique padr√µes, correla√ß√µes e o que os dados est√£o nos dizendo.
Considere o contexto de neg√≥cio em sua interpreta√ß√£o."""),
        ("user", """Pontos de dados extra√≠dos:
{extracao}

Contexto de neg√≥cio: {contexto}

Interpreta√ß√£o:""")
    ])

    resultados["interpretacao"] = executar_passo_cadeia(
        prompt_interpretacao,
        {"extracao": resultados["extracao"], "contexto": contexto_negocio},
        "Interpreta√ß√£o",
        temperature=0.4
    )

    # Passo 3: Recomendar
    print("\n   Passo 3: Gerando recomenda√ß√µes...")
    prompt_recomendacao = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um conselheiro estrat√©gico de neg√≥cios. Baseado na an√°lise de dados,
forne√ßa recomenda√ß√µes espec√≠ficas e acion√°veis.
Priorize por impacto e viabilidade. Inclua tanto vit√≥rias r√°pidas quanto estrat√©gias de longo prazo."""),
        ("user", """Extra√ß√£o de dados:
{extracao}

Interpreta√ß√£o:
{interpretacao}

Contexto de neg√≥cio: {contexto}

Recomenda√ß√µes:""")
    ])

    resultados["recomendacoes"] = executar_passo_cadeia(
        prompt_recomendacao,
        {
            "extracao": resultados["extracao"],
            "interpretacao": resultados["interpretacao"],
            "contexto": contexto_negocio
        },
        "Recomenda√ß√£o",
        temperature=0.5
    )

    return resultados


def cadeia_traducao_localizacao(texto: str, idioma_origem: str, idioma_destino: str, cultura_destino: str) -> dict:
    """
    Cadeia de tradu√ß√£o e localiza√ß√£o: Traduzir -> Adaptar -> Verificar

    Passo 1: Tradu√ß√£o direta
    Passo 2: Adapta√ß√£o cultural
    Passo 3: Verifica√ß√£o de qualidade
    """
    resultados = {}

    # Passo 1: Traduzir
    print("\n   Passo 1: Traduzindo...")
    prompt_traducao = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um tradutor profissional. Traduza o texto com precis√£o
de {idioma_origem} para {idioma_destino}. Mantenha o significado e tom originais."""),
        ("user", """Texto para traduzir:
{texto}

Tradu√ß√£o:""")
    ])

    resultados["traducao"] = executar_passo_cadeia(
        prompt_traducao,
        {"texto": texto, "idioma_origem": idioma_origem, "idioma_destino": idioma_destino},
        "Tradu√ß√£o",
        temperature=0.3
    )

    # Passo 2: Adaptar
    print("\n   Passo 2: Adapta√ß√£o cultural...")
    prompt_adaptacao = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em localiza√ß√£o para {cultura}.
Adapte a tradu√ß√£o para ser culturalmente apropriada:
- Ajuste express√µes idiom√°ticas
- Considere costumes e sensibilidades locais
- Adapte refer√™ncias que podem n√£o traduzir bem
- Mantenha fluxo natural de linguagem para falantes nativos"""),
        ("user", """Tradu√ß√£o para adaptar:
{traducao}

Vers√£o culturalmente adaptada:""")
    ])

    resultados["adaptacao"] = executar_passo_cadeia(
        prompt_adaptacao,
        {"traducao": resultados["traducao"], "cultura": cultura_destino},
        "Adapta√ß√£o",
        temperature=0.4
    )

    # Passo 3: Verificar
    print("\n   Passo 3: Verifica√ß√£o de qualidade...")
    prompt_verificacao = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em garantia de qualidade para conte√∫do em {idioma_destino}.
Revise o texto localizado e:
1. Verifique se h√° problemas de tradu√ß√£o remanescentes
2. Verifique apropria√ß√£o cultural
3. Garanta fluxo natural de linguagem
4. Fa√ßa corre√ß√µes finais

Forne√ßa a vers√£o final verificada e um breve relat√≥rio de qualidade."""),
        ("user", """Original ({idioma_origem}):
{original}

Vers√£o localizada:
{adaptacao}

Vers√£o final verificada e notas de qualidade:""")
    ])

    resultados["verificado"] = executar_passo_cadeia(
        prompt_verificacao,
        {
            "original": texto,
            "adaptacao": resultados["adaptacao"],
            "idioma_origem": idioma_origem,
            "idioma_destino": idioma_destino
        },
        "Verifica√ß√£o",
        temperature=0.2
    )

    return resultados


def main():
    print("=" * 60)
    print("PROMPT CHAINING (ENCADEAMENTO DE PROMPTS) - Demo")
    print("=" * 60)

    # Reseta rastreador
    token_tracker.reset()

    # Exemplo 1: Pesquisar-Analisar-Resumir
    print("\nüîç PESQUISAR -> ANALISAR -> RESUMIR")
    print("-" * 40)

    topico = "O impacto da intelig√™ncia artificial no diagn√≥stico m√©dico"
    print(f"\nT√≥pico: {topico}")

    resultados = pesquisar_analisar_resumir(topico)

    print(f"\nüìã RESUMO EXECUTIVO:")
    print("-" * 40)
    print(resultados["resumo"])

    # Exemplo 2: Pipeline de Cria√ß√£o de Conte√∫do
    print("\n\n‚úçÔ∏è PIPELINE DE CRIA√á√ÉO DE CONTE√öDO")
    print("-" * 40)

    topico_conteudo = "5 Dicas de Produtividade para Trabalhadores Remotos"
    publico = "profissionais do conhecimento de 25-45 anos"

    print(f"\nT√≥pico: {topico_conteudo}")
    print(f"P√∫blico: {publico}")

    resultados = pipeline_criacao_conteudo(topico_conteudo, publico, "artigo de blog")

    print(f"\nüìã CONTE√öDO FINAL:")
    print("-" * 40)
    print(resultados["final"][:1500] + "..." if len(resultados["final"]) > 1500 else resultados["final"])

    # Exemplo 3: Cadeia de Insight de Dados
    print("\n\nüìä CADEIA DE INSIGHT DE DADOS")
    print("-" * 40)

    desc_dados = """
    Relat√≥rio de Vendas Q3:
    - Receita total: R$12M (aumento de 15% do Q2)
    - Novos clientes: 340 (queda de 8% do Q2)
    - Taxa de reten√ß√£o de clientes: 92%
    - Tamanho m√©dio de neg√≥cio: R$35.290 (aumento de 25%)
    - Dura√ß√£o do ciclo de vendas: 45 dias (aumento de 38 dias)
    - Regi√£o com melhor desempenho: Sudeste (35% da receita)
    - Regi√£o com baixo desempenho: Norte (8% da receita)
    """
    ctx_negocio = "Empresa B2B SaaS mirando empresas de m√©dio porte, meta √© crescimento de 30% ano a ano"

    print(f"\nDados: {desc_dados.strip()}")
    print(f"\nContexto: {ctx_negocio}")

    resultados = cadeia_insight_dados(desc_dados, ctx_negocio)

    print(f"\nüìã RECOMENDA√á√ïES:")
    print("-" * 40)
    print(resultados["recomendacoes"])

    # Exemplo 4: Tradu√ß√£o e Localiza√ß√£o
    print("\n\nüåê TRADU√á√ÉO E LOCALIZA√á√ÉO")
    print("-" * 40)

    texto_original = """
    Our Black Friday sale is a slam dunk! Get up to 50% off everything in the store.
    Don't miss out - these deals are going like hotcakes! Sale runs through Cyber Monday.
    """

    print(f"\nOriginal (Ingl√™s): {texto_original.strip()}")

    resultados = cadeia_traducao_localizacao(
        texto_original,
        idioma_origem="Ingl√™s",
        idioma_destino="Portugu√™s Brasileiro",
        cultura_destino="consumidores brasileiros"
    )

    print(f"\nüìã VERS√ÉO LOCALIZADA:")
    print("-" * 40)
    print(resultados["verificado"])

    # Exibe total de tokens
    print_total_usage(token_tracker, "TOTAL - Prompt Chaining")

    print("\nFim do demo de Prompt Chaining")
    print("=" * 60)


if __name__ == "__main__":
    main()
