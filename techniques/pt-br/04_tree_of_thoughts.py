"""
Tree of Thoughts (ToT)

T√©cnica que explora m√∫ltiplos caminhos de racioc√≠nio em paralelo,
avalia cada um e seleciona o mais promissor. √ötil para problemas
que requerem explora√ß√£o e backtracking.

Casos de uso:
- Planejamento estrat√©gico
- Problemas com m√∫ltiplas solu√ß√µes poss√≠veis
- Jogos e puzzles
- Otimiza√ß√£o de decis√µes
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from langchain_core.prompts import ChatPromptTemplate
from config import (
    get_llm,
    TokenUsage,
    extract_tokens_from_response,
    print_token_usage,
    print_total_usage
)

# Tracker global de tokens para este script
token_tracker = TokenUsage()


def gerar_pensamentos(problema: str, num_pensamentos: int = 3) -> list[str]:
    """Gera m√∫ltiplos caminhos de racioc√≠nio inicial."""
    llm = get_llm(temperature=0.8)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um solucionador criativo de problemas.
Dado um problema, gere {num_pensamentos} abordagens DIFERENTES e INDEPENDENTES para resolv√™-lo.

Cada abordagem deve:
- Ser √∫nica e distinta das outras
- Ter uma l√≥gica clara
- Ser um primeiro passo vi√°vel para a solu√ß√£o

Formato de sa√≠da (use exatamente este formato):
ABORDAGEM 1: [descri√ß√£o da primeira abordagem]
ABORDAGEM 2: [descri√ß√£o da segunda abordagem]
ABORDAGEM 3: [descri√ß√£o da terceira abordagem]"""),
        ("user", "{problema}")
    ])

    chain = prompt | llm
    response = chain.invoke({"problema": problema, "num_pensamentos": num_pensamentos})

    # Extrair e registrar tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "gerar_pensamentos")

    resultado = response.content

    # Parse das abordagens
    linhas = resultado.strip().split("\n")
    abordagens = []
    abordagem_atual = ""

    for linha in linhas:
        if linha.startswith("ABORDAGEM"):
            if abordagem_atual:
                abordagens.append(abordagem_atual.strip())
            abordagem_atual = linha.split(":", 1)[1] if ":" in linha else linha
        else:
            abordagem_atual += " " + linha

    if abordagem_atual:
        abordagens.append(abordagem_atual.strip())

    return abordagens[:num_pensamentos]


def avaliar_pensamento(problema: str, pensamento: str) -> dict:
    """Avalia a qualidade e viabilidade de um caminho de racioc√≠nio."""
    llm = get_llm(temperature=0.3)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um avaliador cr√≠tico de solu√ß√µes.
Avalie a abordagem proposta para resolver o problema.

Crit√©rios de avalia√ß√£o (0-10 cada):
1. VIABILIDADE: A abordagem √© realiz√°vel?
2. EFICI√äNCIA: A abordagem √© eficiente?
3. COMPLETUDE: A abordagem resolve o problema completamente?
4. CRIATIVIDADE: A abordagem √© inovadora?

Formato de resposta:
VIABILIDADE: [0-10]
EFICI√äNCIA: [0-10]
COMPLETUDE: [0-10]
CRIATIVIDADE: [0-10]
TOTAL: [soma/40]
JUSTIFICATIVA: [breve explica√ß√£o]
PR√ìXIMO_PASSO: [sugest√£o de como continuar esta abordagem]"""),
        ("user", "PROBLEMA: {problema}\n\nABORDAGEM PROPOSTA: {pensamento}")
    ])

    chain = prompt | llm
    response = chain.invoke({"problema": problema, "pensamento": pensamento})

    # Extrair e registrar tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "avaliar_pensamento")

    resultado = response.content

    # Parse b√°sico para extrair a pontua√ß√£o total
    linhas = resultado.strip().split("\n")
    avaliacao = {
        "texto_completo": resultado,
        "pontuacao": 0,
        "proximo_passo": ""
    }

    for linha in linhas:
        if linha.startswith("TOTAL:"):
            try:
                # Extrai n√∫mero do formato "XX/40" ou similar
                valor = linha.split(":")[1].strip().split("/")[0]
                avaliacao["pontuacao"] = float(valor)
            except (ValueError, IndexError):
                avaliacao["pontuacao"] = 0
        elif linha.startswith("PR√ìXIMO_PASSO:"):
            avaliacao["proximo_passo"] = linha.split(":", 1)[1].strip()

    return avaliacao


def expandir_pensamento(problema: str, pensamento: str, proximo_passo: str) -> str:
    """Expande um pensamento promissor para o pr√≥ximo n√≠vel."""
    llm = get_llm(temperature=0.5)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um solucionador met√≥dico de problemas.
Continue desenvolvendo a abordagem proposta, seguindo a sugest√£o de pr√≥ximo passo.

Desenvolva o racioc√≠nio de forma detalhada, mostrando:
1. Como implementar o pr√≥ximo passo
2. Poss√≠veis obst√°culos e como super√°-los
3. Resultados esperados desta etapa"""),
        ("user", """PROBLEMA: {problema}

ABORDAGEM ATUAL: {pensamento}

PR√ìXIMO PASSO SUGERIDO: {proximo_passo}

Continue o desenvolvimento:""")
    ])

    chain = prompt | llm
    response = chain.invoke({
        "problema": problema,
        "pensamento": pensamento,
        "proximo_passo": proximo_passo
    })

    # Extrair e registrar tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "expandir_pensamento")

    return response.content


def sintetizar_solucao(problema: str, melhor_caminho: list[str]) -> str:
    """Sintetiza a solu√ß√£o final a partir do melhor caminho encontrado."""
    llm = get_llm(temperature=0.3)

    caminho_texto = "\n\n".join([f"ETAPA {i+1}:\n{etapa}" for i, etapa in enumerate(melhor_caminho)])

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em s√≠ntese de solu√ß√µes.
Com base no caminho de racioc√≠nio desenvolvido, apresente a solu√ß√£o final de forma clara e estruturada.

A solu√ß√£o deve incluir:
1. RESUMO: Vis√£o geral da solu√ß√£o
2. PASSOS DE IMPLEMENTA√á√ÉO: Lista ordenada de a√ß√µes
3. RECURSOS NECESS√ÅRIOS: O que √© preciso para implementar
4. RESULTADO ESPERADO: O que ser√° alcan√ßado
5. RISCOS E MITIGA√á√ïES: Poss√≠veis problemas e como evit√°-los"""),
        ("user", "PROBLEMA: {problema}\n\nCAMINHO DE RACIOC√çNIO:\n{caminho}")
    ])

    chain = prompt | llm
    response = chain.invoke({"problema": problema, "caminho": caminho_texto})

    # Extrair e registrar tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "sintetizar_solucao")

    return response.content


def tree_of_thoughts(problema: str, profundidade: int = 2) -> str:
    """
    Implementa o algoritmo Tree of Thoughts completo.

    Args:
        problema: O problema a ser resolvido
        profundidade: Quantos n√≠veis de expans√£o explorar

    Returns:
        A solu√ß√£o sintetizada
    """
    print(f"\nüå≥ Iniciando Tree of Thoughts (profundidade={profundidade})")
    print("=" * 50)

    # Fase 1: Gerar pensamentos iniciais
    print("\nüìù Fase 1: Gerando abordagens iniciais...")
    pensamentos = gerar_pensamentos(problema, num_pensamentos=3)

    for i, p in enumerate(pensamentos, 1):
        print(f"\n  Abordagem {i}: {p[:100]}...")

    # Fase 2: Avaliar e selecionar o melhor
    print("\n‚öñÔ∏è Fase 2: Avaliando abordagens...")
    avaliacoes = []

    for i, pensamento in enumerate(pensamentos, 1):
        avaliacao = avaliar_pensamento(problema, pensamento)
        avaliacoes.append({
            "pensamento": pensamento,
            "avaliacao": avaliacao
        })
        print(f"\n  Abordagem {i}: Pontua√ß√£o = {avaliacao['pontuacao']}/40")

    # Ordenar por pontua√ß√£o e selecionar o melhor
    avaliacoes.sort(key=lambda x: x["avaliacao"]["pontuacao"], reverse=True)
    melhor = avaliacoes[0]

    print(f"\n‚úÖ Melhor abordagem selecionada (pontua√ß√£o: {melhor['avaliacao']['pontuacao']}/40)")

    # Fase 3: Expandir o melhor caminho
    caminho = [melhor["pensamento"]]
    pensamento_atual = melhor["pensamento"]
    proximo_passo = melhor["avaliacao"]["proximo_passo"]

    for nivel in range(profundidade):
        print(f"\nüîç Fase 3.{nivel+1}: Expandindo n√≠vel {nivel+1}...")

        expansao = expandir_pensamento(problema, pensamento_atual, proximo_passo)
        caminho.append(expansao)

        # Avaliar a expans√£o para obter pr√≥ximo passo
        avaliacao = avaliar_pensamento(problema, expansao)
        proximo_passo = avaliacao["proximo_passo"]
        pensamento_atual = expansao

        print(f"  Expans√£o conclu√≠da (pontua√ß√£o: {avaliacao['pontuacao']}/40)")

    # Fase 4: Sintetizar solu√ß√£o
    print("\nüìã Fase 4: Sintetizando solu√ß√£o final...")
    solucao = sintetizar_solucao(problema, caminho)

    return solucao


def main():
    print("=" * 60)
    print("TREE OF THOUGHTS (ToT) - Demonstra√ß√£o")
    print("=" * 60)

    # Reset do tracker
    token_tracker.reset()

    # Problema complexo para demonstra√ß√£o
    problema = """
    Uma startup de tecnologia com 15 funcion√°rios precisa decidir
    como expandir suas opera√ß√µes. Atualmente opera apenas no Brasil,
    tem um produto SaaS com 500 clientes pagantes e faturamento de
    R$ 200 mil/m√™s. O objetivo √© triplicar o faturamento em 18 meses.

    Restri√ß√µes:
    - Budget dispon√≠vel para investimento: R$ 1 milh√£o
    - Time t√©cnico j√° est√° no limite da capacidade
    - Produto ainda tem d√©bito t√©cnico significativo

    Qual a melhor estrat√©gia de crescimento?
    """

    print(f"\nüìå PROBLEMA:\n{problema.strip()}")

    # Executar Tree of Thoughts
    solucao = tree_of_thoughts(problema, profundidade=2)

    print("\n" + "=" * 60)
    print("üéØ SOLU√á√ÉO FINAL")
    print("=" * 60)
    print(solucao)

    # Exibir total de tokens
    print_total_usage(token_tracker, "TOTAL - Tree of Thoughts")

    print("\nFim da demonstra√ß√£o Tree of Thoughts")
    print("=" * 60)


if __name__ == "__main__":
    main()
