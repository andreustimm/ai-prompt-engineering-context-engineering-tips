"""
Self-Refine Prompting (Auto-Refinamento)

T√©cnica onde o modelo gera uma resposta inicial, critica-a,
e melhora iterativamente baseado em seu pr√≥prio feedback at√© ficar satisfat√≥rio.

Casos de uso:
- Escrita e melhoria de conte√∫do
- Otimiza√ß√£o de c√≥digo
- Explica√ß√µes detalhadas
- Gera√ß√£o de conte√∫do criativo
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from langchain_core.prompts import ChatPromptTemplate
from config import (
    get_llm,
    TokenUsage,
    extract_tokens_from_response,
    print_token_usage,
    print_total_usage
)

# Rastreador global de tokens para este script
token_tracker = TokenUsage()


def gerar_resposta_inicial(tarefa: str, contexto: str = "") -> str:
    """Gera uma resposta inicial para a tarefa."""
    llm = get_llm(temperature=0.7)

    if contexto:
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um assistente habilidoso. Complete a tarefa dada da melhor forma poss√≠vel.
Considere o contexto fornecido em sua resposta."""),
            ("user", """Contexto: {contexto}

Tarefa: {tarefa}

Resposta:""")
        ])
        inputs = {"tarefa": tarefa, "contexto": contexto}
    else:
        prompt = ChatPromptTemplate.from_messages([
            ("system", "Voc√™ √© um assistente habilidoso. Complete a tarefa dada da melhor forma poss√≠vel."),
            ("user", """Tarefa: {tarefa}

Resposta:""")
        ])
        inputs = {"tarefa": tarefa}

    chain = prompt | llm
    response = chain.invoke(inputs)

    # Extrai e registra tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "Inicial")

    return response.content


def criticar_resposta(tarefa: str, resposta: str, criterios: list[str] = None) -> str:
    """Critica uma resposta e identifica √°reas para melhoria."""
    llm = get_llm(temperature=0.3)

    criterios_padrao = [
        "Precis√£o e corre√ß√£o",
        "Clareza e legibilidade",
        "Completude",
        "Estrutura e organiza√ß√£o",
        "Relev√¢ncia para a tarefa"
    ]

    criterios = criterios or criterios_padrao
    texto_criterios = "\n".join([f"- {c}" for c in criterios])

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um revisor cr√≠tico. Analise a resposta dada e forne√ßa feedback espec√≠fico e acion√°vel.
Seja construtivo mas minucioso em identificar fraquezas e √°reas para melhoria.

Avalie com base nestes crit√©rios:
{criterios}

Formate sua cr√≠tica como:
PONTOS FORTES:
- [liste pontos fortes]

PONTOS FRACOS:
- [liste pontos fracos]

MELHORIAS ESPEC√çFICAS:
- [liste mudan√ßas espec√≠ficas a fazer]"""),
        ("user", """Tarefa Original: {tarefa}

Resposta a Criticar:
{resposta}

Forne√ßa sua cr√≠tica detalhada:""")
    ])

    chain = prompt | llm
    result = chain.invoke({
        "tarefa": tarefa,
        "resposta": resposta,
        "criterios": texto_criterios
    })

    # Extrai e registra tokens
    input_tokens, output_tokens = extract_tokens_from_response(result)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "Cr√≠tica")

    return result.content


def refinar_resposta(tarefa: str, resposta: str, critica: str) -> str:
    """Refina uma resposta baseada na cr√≠tica."""
    llm = get_llm(temperature=0.5)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um assistente habilidoso melhorando seu trabalho anterior.
Baseado na cr√≠tica fornecida, crie uma vers√£o melhorada da resposta.
Aborde todos os pontos fracos e incorpore as melhorias sugeridas."""),
        ("user", """Tarefa Original: {tarefa}

Resposta Anterior:
{resposta}

Cr√≠tica e Feedback:
{critica}

Resposta Melhorada:""")
    ])

    chain = prompt | llm
    result = chain.invoke({
        "tarefa": tarefa,
        "resposta": resposta,
        "critica": critica
    })

    # Extrai e registra tokens
    input_tokens, output_tokens = extract_tokens_from_response(result)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "Refinamento")

    return result.content


def verificar_se_satisfatorio(tarefa: str, resposta: str, pontuacao_minima: int = 8) -> tuple[bool, int, str]:
    """Verifica se a resposta √© satisfat√≥ria (pontua√ß√£o >= pontua√ß√£o_minima)."""
    llm = get_llm(temperature=0)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um avaliador de qualidade. Avalie a resposta em uma escala de 1-10.
Seja rigoroso e objetivo em sua avalia√ß√£o.

Formato de sa√≠da (exatamente):
PONTUA√á√ÉO: [n√∫mero 1-10]
RAZ√ÉO: [breve explica√ß√£o]"""),
        ("user", """Tarefa: {tarefa}

Resposta a Avaliar:
{resposta}

Avalia√ß√£o:""")
    ])

    chain = prompt | llm
    result = chain.invoke({"tarefa": tarefa, "resposta": resposta})

    # Extrai e registra tokens
    input_tokens, output_tokens = extract_tokens_from_response(result)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "Avalia√ß√£o")

    # Analisa pontua√ß√£o
    content = result.content
    pontuacao = 5  # Padr√£o
    razao = ""

    for linha in content.split('\n'):
        if 'PONTUA√á√ÉO:' in linha.upper() or 'SCORE:' in linha.upper():
            try:
                pontuacao_str = linha.split(':')[1].strip()
                pontuacao = int(''.join(filter(str.isdigit, pontuacao_str[:3])))
            except (ValueError, IndexError):
                pass
        elif 'RAZ√ÉO:' in linha.upper() or 'REASON:' in linha.upper():
            razao = linha.split(':', 1)[1].strip() if ':' in linha else ""

    return pontuacao >= pontuacao_minima, pontuacao, razao


def auto_refinar(tarefa: str, max_iteracoes: int = 3, pontuacao_minima: int = 8, criterios: list[str] = None) -> dict:
    """
    Executa o loop de auto-refinamento.

    Args:
        tarefa: A tarefa a completar
        max_iteracoes: M√°ximo de itera√ß√µes de refinamento
        pontuacao_minima: Pontua√ß√£o m√≠nima aceit√°vel (1-10)
        criterios: Crit√©rios de avalia√ß√£o personalizados

    Retorna:
        Dicion√°rio com itera√ß√µes, resposta final e pontua√ß√£o
    """
    iteracoes = []

    print("\n   Gerando resposta inicial...")
    resposta_atual = gerar_resposta_inicial(tarefa)
    iteracoes.append({"resposta": resposta_atual, "critica": None, "pontuacao": None})

    for i in range(max_iteracoes):
        print(f"\n   Verificando qualidade (itera√ß√£o {i+1})...")
        satisfatorio, pontuacao, razao = verificar_se_satisfatorio(tarefa, resposta_atual, pontuacao_minima)
        iteracoes[-1]["pontuacao"] = pontuacao
        iteracoes[-1]["razao_pontuacao"] = razao

        print(f"      Pontua√ß√£o: {pontuacao}/10 - {razao}")

        if satisfatorio:
            print(f"   ‚úì Resposta satisfat√≥ria (pontua√ß√£o >= {pontuacao_minima})")
            break

        if i < max_iteracoes - 1:
            print(f"\n   Criticando resposta...")
            critica = criticar_resposta(tarefa, resposta_atual, criterios)
            iteracoes[-1]["critica"] = critica

            print(f"\n   Refinando baseado na cr√≠tica...")
            resposta_atual = refinar_resposta(tarefa, resposta_atual, critica)
            iteracoes.append({"resposta": resposta_atual, "critica": None, "pontuacao": None})

    # Avalia√ß√£o final se o loop completou
    if iteracoes[-1]["pontuacao"] is None:
        _, pontuacao, razao = verificar_se_satisfatorio(tarefa, resposta_atual, pontuacao_minima)
        iteracoes[-1]["pontuacao"] = pontuacao
        iteracoes[-1]["razao_pontuacao"] = razao

    return {
        "iteracoes": iteracoes,
        "resposta_final": resposta_atual,
        "pontuacao_final": iteracoes[-1]["pontuacao"],
        "num_iteracoes": len(iteracoes)
    }


def melhorar_escrita(texto: str, estilo: str = "profissional") -> dict:
    """Melhora um texto usando auto-refinamento."""
    tarefa = f"Reescreva o seguinte texto em estilo {estilo} mantendo o significado original:\n\n{texto}"
    criterios = [
        "Gram√°tica e ortografia",
        "Tom corresponde ao estilo solicitado",
        "Fluidez e legibilidade",
        "Concis√£o",
        "Engajamento"
    ]
    return auto_refinar(tarefa, max_iteracoes=3, criterios=criterios)


def otimizar_codigo(codigo: str, linguagem: str = "Python") -> dict:
    """Otimiza c√≥digo usando auto-refinamento."""
    tarefa = f"Otimize este c√≥digo {linguagem} para legibilidade, efici√™ncia e boas pr√°ticas:\n\n{codigo}"
    criterios = [
        "Corre√ß√£o do c√≥digo",
        "Legibilidade e clareza",
        "Efici√™ncia",
        "Segue boas pr√°ticas",
        "Tratamento de erros adequado"
    ]
    return auto_refinar(tarefa, max_iteracoes=3, criterios=criterios)


def melhorar_explicacao(topico: str, audiencia: str = "geral") -> dict:
    """Cria e melhora uma explica√ß√£o usando auto-refinamento."""
    tarefa = f"Explique {topico} para uma audi√™ncia {audiencia} de forma clara e envolvente"
    criterios = [
        "Precis√£o",
        "Apropriado para o p√∫blico-alvo",
        "Usa exemplos √∫teis",
        "Estrutura clara",
        "Apresenta√ß√£o envolvente"
    ]
    return auto_refinar(tarefa, max_iteracoes=3, criterios=criterios)


def main():
    print("=" * 60)
    print("SELF-REFINE PROMPTING (AUTO-REFINAMENTO) - Demo")
    print("=" * 60)

    # Reseta rastreador
    token_tracker.reset()

    # Exemplo 1: Melhoria de Escrita
    print("\n‚úçÔ∏è MELHORIA DE ESCRITA")
    print("-" * 40)

    texto_original = """
    A reuni√£o foi boa. A gente conversou sobre algumas coisas e tomou umas decis√µes.
    Todo mundo pareceu concordar na maioria. Vamos fazer as coisas diferente agora.
    O projeto deve ficar pronto logo espero.
    """

    print(f"\nTexto Original:\n{texto_original.strip()}")
    print("\nMelhorando para estilo profissional...")

    resultado = melhorar_escrita(texto_original, estilo="profissional empresarial")

    print(f"\nüìã VERS√ÉO FINAL (Pontua√ß√£o: {resultado['pontuacao_final']}/10):")
    print("-" * 40)
    print(resultado["resposta_final"])
    print(f"\n   Itera√ß√µes necess√°rias: {resultado['num_iteracoes']}")

    # Exemplo 2: Otimiza√ß√£o de C√≥digo
    print("\n\nüíª OTIMIZA√á√ÉO DE C√ìDIGO")
    print("-" * 40)

    codigo_original = '''
def encontrar_duplicados(lista):
    duplicados = []
    for i in range(len(lista)):
        for j in range(i + 1, len(lista)):
            if lista[i] == lista[j]:
                if lista[i] not in duplicados:
                    duplicados.append(lista[i])
    return duplicados
'''

    print(f"\nC√≥digo Original:{codigo_original}")
    print("Otimizando...")

    resultado = otimizar_codigo(codigo_original, linguagem="Python")

    print(f"\nüìã C√ìDIGO OTIMIZADO (Pontua√ß√£o: {resultado['pontuacao_final']}/10):")
    print("-" * 40)
    print(resultado["resposta_final"])
    print(f"\n   Itera√ß√µes necess√°rias: {resultado['num_iteracoes']}")

    # Exemplo 3: Melhoria de Explica√ß√£o
    print("\n\nüìö MELHORIA DE EXPLICA√á√ÉO")
    print("-" * 40)

    topico = "como a tecnologia blockchain funciona"
    audiencia = "executivos de neg√≥cios n√£o t√©cnicos"

    print(f"\nT√≥pico: {topico}")
    print(f"P√∫blico-Alvo: {audiencia}")
    print("\nGerando e refinando explica√ß√£o...")

    resultado = melhorar_explicacao(topico, audiencia)

    print(f"\nüìã EXPLICA√á√ÉO FINAL (Pontua√ß√£o: {resultado['pontuacao_final']}/10):")
    print("-" * 40)
    print(resultado["resposta_final"])
    print(f"\n   Itera√ß√µes necess√°rias: {resultado['num_iteracoes']}")

    # Exibe total de tokens
    print_total_usage(token_tracker, "TOTAL - Self-Refine Prompting")

    print("\nFim do demo de Self-Refine")
    print("=" * 60)


if __name__ == "__main__":
    main()
