"""
Skeleton of Thought (SoT)

T√©cnica que primeiro gera um "esqueleto" da resposta (estrutura/t√≥picos)
e depois expande cada parte. Permite paraleliza√ß√£o e respostas mais
organizadas.

Casos de uso:
- Gera√ß√£o de conte√∫do longo
- Respostas estruturadas
- Artigos e documenta√ß√£o
- An√°lises detalhadas
"""

import sys
import asyncio
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from langchain_core.prompts import ChatPromptTemplate
from config import (
    get_llm,
    TokenUsage,
    extract_tokens_from_response,
    print_token_usage,
    print_total_usage
)

# Tracker global de tokens para este script
token_tracker = TokenUsage()


def gerar_esqueleto(tema: str, contexto: str = "") -> list[str]:
    """
    Fase 1: Gera o esqueleto (lista de t√≥picos) para um tema.

    Args:
        tema: O tema principal a ser desenvolvido
        contexto: Contexto adicional opcional

    Returns:
        Lista de t√≥picos que formam o esqueleto
    """
    llm = get_llm(temperature=0.5)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um especialista em estrutura√ß√£o de conte√∫do.
Dado um tema, crie um esqueleto (outline) com os principais t√≥picos a serem abordados.

Regras:
- Liste entre 4 e 7 t√≥picos principais
- Cada t√≥pico deve ser claro e focado
- Os t√≥picos devem seguir uma ordem l√≥gica
- Use t√≠tulos curtos e descritivos

Formato de sa√≠da (um t√≥pico por linha):
1. [Primeiro t√≥pico]
2. [Segundo t√≥pico]
3. [Terceiro t√≥pico]
..."""),
        ("user", "TEMA: {tema}\n{contexto_texto}")
    ])

    contexto_texto = f"CONTEXTO: {contexto}" if contexto else ""

    chain = prompt | llm
    response = chain.invoke({"tema": tema, "contexto_texto": contexto_texto})

    # Extrair e registrar tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "gerar_esqueleto")

    resultado = response.content

    # Parse dos t√≥picos
    linhas = resultado.strip().split("\n")
    topicos = []

    for linha in linhas:
        # Remove numera√ß√£o e limpa
        linha = linha.strip()
        if linha and linha[0].isdigit():
            # Remove "1.", "2.", etc.
            partes = linha.split(".", 1)
            if len(partes) > 1:
                topico = partes[1].strip()
                if topico:
                    topicos.append(topico)
        elif linha and not linha[0].isdigit():
            # Linha sem n√∫mero, mas pode ser t√≥pico
            if linha.startswith("-"):
                topicos.append(linha[1:].strip())

    return topicos


def expandir_topico(tema: str, topico: str, contexto: str = "") -> str:
    """
    Fase 2: Expande um t√≥pico espec√≠fico do esqueleto.

    Args:
        tema: O tema principal (para contexto)
        topico: O t√≥pico a ser expandido
        contexto: Contexto adicional opcional

    Returns:
        Texto expandido do t√≥pico
    """
    llm = get_llm(temperature=0.6)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um escritor especializado em criar conte√∫do informativo.
Expanda o t√≥pico fornecido de forma clara e detalhada.

Regras:
- Escreva 2-3 par√°grafos sobre o t√≥pico
- Seja informativo e preciso
- Use exemplos quando apropriado
- Mantenha o foco no tema principal
- N√£o repita informa√ß√µes do t√≠tulo do t√≥pico"""),
        ("user", "TEMA PRINCIPAL: {tema}\n\nT√ìPICO A EXPANDIR: {topico}\n{contexto_texto}")
    ])

    contexto_texto = f"\nCONTEXTO ADICIONAL: {contexto}" if contexto else ""

    chain = prompt | llm
    response = chain.invoke({
        "tema": tema,
        "topico": topico,
        "contexto_texto": contexto_texto
    })

    # Extrair e registrar tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, f"expandir: {topico[:20]}...")

    return response.content


async def expandir_topico_async(llm, tema: str, topico: str, contexto: str = "") -> dict:
    """Vers√£o ass√≠ncrona da expans√£o de t√≥pico para paraleliza√ß√£o."""

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um escritor especializado em criar conte√∫do informativo.
Expanda o t√≥pico fornecido de forma clara e detalhada.

Regras:
- Escreva 2-3 par√°grafos sobre o t√≥pico
- Seja informativo e preciso
- Use exemplos quando apropriado
- Mantenha o foco no tema principal"""),
        ("user", "TEMA PRINCIPAL: {tema}\n\nT√ìPICO A EXPANDIR: {topico}")
    ])

    chain = prompt | llm

    # Executa em thread pool para n√£o bloquear
    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(
        None,
        lambda: chain.invoke({"tema": tema, "topico": topico})
    )

    # Extrair tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)

    return {
        "topico": topico,
        "conteudo": response.content,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens
    }


async def skeleton_of_thought_async(tema: str, contexto: str = "") -> str:
    """
    Implementa√ß√£o ass√≠ncrona do Skeleton of Thought com expans√£o paralela.

    Args:
        tema: O tema a ser desenvolvido
        contexto: Contexto adicional opcional

    Returns:
        Texto completo gerado
    """
    print("\nü¶¥ Iniciando Skeleton of Thought (Async)")
    print("=" * 50)

    # Fase 1: Gerar esqueleto
    print("\nüìã Fase 1: Gerando esqueleto...")
    topicos = gerar_esqueleto(tema, contexto)

    print(f"  Esqueleto gerado com {len(topicos)} t√≥picos:")
    for i, t in enumerate(topicos, 1):
        print(f"    {i}. {t}")

    # Fase 2: Expandir t√≥picos em paralelo
    print("\n‚úçÔ∏è Fase 2: Expandindo t√≥picos em paralelo...")

    llm = get_llm(temperature=0.6)

    # Criar tarefas ass√≠ncronas para cada t√≥pico
    tarefas = [
        expandir_topico_async(llm, tema, topico, contexto)
        for topico in topicos
    ]

    # Executar todas em paralelo
    resultados = await asyncio.gather(*tarefas)

    # Mostrar tokens por t√≥pico
    for resultado in resultados:
        print_token_usage(
            resultado["input_tokens"],
            resultado["output_tokens"],
            f"expandir: {resultado['topico'][:20]}..."
        )

    # Ordenar resultados na ordem original dos t√≥picos
    resultados_ordenados = sorted(
        resultados,
        key=lambda x: topicos.index(x["topico"])
    )

    print(f"  {len(resultados)} se√ß√µes expandidas!")

    # Fase 3: Montar documento final
    print("\nüìÑ Fase 3: Montando documento final...")

    documento = f"# {tema}\n\n"

    for i, resultado in enumerate(resultados_ordenados, 1):
        documento += f"## {i}. {resultado['topico']}\n\n"
        documento += f"{resultado['conteudo']}\n\n"

    return documento


def skeleton_of_thought_sync(tema: str, contexto: str = "") -> str:
    """
    Implementa√ß√£o s√≠ncrona do Skeleton of Thought.

    Args:
        tema: O tema a ser desenvolvido
        contexto: Contexto adicional opcional

    Returns:
        Texto completo gerado
    """
    print("\nü¶¥ Iniciando Skeleton of Thought (Sync)")
    print("=" * 50)

    # Fase 1: Gerar esqueleto
    print("\nüìã Fase 1: Gerando esqueleto...")
    topicos = gerar_esqueleto(tema, contexto)

    print(f"  Esqueleto gerado com {len(topicos)} t√≥picos:")
    for i, t in enumerate(topicos, 1):
        print(f"    {i}. {t}")

    # Fase 2: Expandir cada t√≥pico sequencialmente
    print("\n‚úçÔ∏è Fase 2: Expandindo t√≥picos...")

    secoes = []
    for i, topico in enumerate(topicos, 1):
        print(f"  Expandindo t√≥pico {i}/{len(topicos)}: {topico[:30]}...")
        conteudo = expandir_topico(tema, topico, contexto)
        secoes.append({"topico": topico, "conteudo": conteudo})

    # Fase 3: Montar documento final
    print("\nüìÑ Fase 3: Montando documento final...")

    documento = f"# {tema}\n\n"

    for i, secao in enumerate(secoes, 1):
        documento += f"## {i}. {secao['topico']}\n\n"
        documento += f"{secao['conteudo']}\n\n"

    return documento


def gerar_com_revisao(tema: str, contexto: str = "") -> str:
    """
    Skeleton of Thought com etapa adicional de revis√£o.

    Args:
        tema: O tema a ser desenvolvido
        contexto: Contexto adicional opcional

    Returns:
        Texto final revisado
    """
    # Gerar documento base
    documento = skeleton_of_thought_sync(tema, contexto)

    # Fase de revis√£o
    print("\nüîç Fase Extra: Revisando documento...")

    llm = get_llm(temperature=0.3)

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um editor profissional.
Revise o documento fornecido e fa√ßa melhorias em:
- Coes√£o entre se√ß√µes
- Clareza do texto
- Corre√ß√£o de repeti√ß√µes
- Adi√ß√£o de transi√ß√µes entre t√≥picos

Retorne o documento completo revisado, mantendo a estrutura de t√≠tulos."""),
        ("user", "{documento}")
    ])

    chain = prompt | llm
    response = chain.invoke({"documento": documento})

    # Extrair e registrar tokens
    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "revisao")

    return response.content


def main():
    print("=" * 60)
    print("SKELETON OF THOUGHT (SoT) - Demonstra√ß√£o")
    print("=" * 60)

    # Reset do tracker
    token_tracker.reset()

    # Tema para demonstra√ß√£o
    tema = "Intelig√™ncia Artificial na Medicina: Aplica√ß√µes e Desafios"
    contexto = "Foco em aplica√ß√µes pr√°ticas j√° em uso e desafios √©ticos"

    print(f"\nüìå TEMA: {tema}")
    print(f"üìù CONTEXTO: {contexto}")

    # Demonstra√ß√£o 1: Vers√£o S√≠ncrona
    print("\n" + "-" * 60)
    print("DEMONSTRA√á√ÉO 1: Vers√£o S√≠ncrona")
    print("-" * 60)

    documento_sync = skeleton_of_thought_sync(tema, contexto)

    print("\n" + "=" * 60)
    print("üìÑ DOCUMENTO GERADO (Vers√£o S√≠ncrona)")
    print("=" * 60)
    print(documento_sync)

    # Demonstra√ß√£o 2: Vers√£o Ass√≠ncrona (se suportado)
    print("\n" + "-" * 60)
    print("DEMONSTRA√á√ÉO 2: Vers√£o Ass√≠ncrona (Paralela)")
    print("-" * 60)

    tema2 = "Boas Pr√°ticas de Seguran√ßa em Aplica√ß√µes Web"

    try:
        documento_async = asyncio.run(skeleton_of_thought_async(tema2, ""))

        print("\n" + "=" * 60)
        print("üìÑ DOCUMENTO GERADO (Vers√£o Ass√≠ncrona)")
        print("=" * 60)
        print(documento_async)
    except Exception as e:
        print(f"  Erro na vers√£o ass√≠ncrona: {e}")
        print("  Usando vers√£o s√≠ncrona como fallback...")
        documento_async = skeleton_of_thought_sync(tema2, "")
        print(documento_async)

    # Exibir total de tokens
    print_total_usage(token_tracker, "TOTAL - Skeleton of Thought")

    print("\nFim da demonstra√ß√£o Skeleton of Thought")
    print("=" * 60)


if __name__ == "__main__":
    main()
