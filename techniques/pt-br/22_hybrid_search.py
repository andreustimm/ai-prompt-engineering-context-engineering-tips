"""
Busca H√≠brida (BM25 + Vetor)

Combina busca por palavras-chave (BM25) com busca sem√¢ntica (vetores)
para melhor precis√£o de recupera√ß√£o. Esta abordagem aproveita os pontos
fortes de ambos os m√©todos.

Componentes:
- Retriever BM25: Correspond√™ncia tradicional de palavras-chave (baseado em TF-IDF)
- Retriever de Vetores: Busca por similaridade sem√¢ntica
- Retriever Ensemble: Combina resultados usando Reciprocal Rank Fusion

Casos de uso:
- Documenta√ß√£o t√©cnica com terminologia espec√≠fica
- Documentos legais com requisitos precisos de palavras-chave
- Busca de produtos combinando correspond√™ncias exatas com compreens√£o sem√¢ntica
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from langchain_core.prompts import ChatPromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# Imports condicionais
try:
    from langchain_community.vectorstores import Chroma
    CHROMA_DISPONIVEL = True
except ImportError:
    CHROMA_DISPONIVEL = False
    print("Aviso: chromadb n√£o instalado. Execute: pip install chromadb")

try:
    from rank_bm25 import BM25Okapi
    BM25_DISPONIVEL = True
except ImportError:
    BM25_DISPONIVEL = False
    print("Aviso: rank-bm25 n√£o instalado. Execute: pip install rank-bm25")

from config import (
    get_llm,
    get_embeddings,
    TokenUsage,
    extract_tokens_from_response,
    print_token_usage,
    print_total_usage
)

# Rastreador global de tokens
token_tracker = TokenUsage()


def carregar_documentos_exemplo() -> list[Document]:
    """Carrega documentos de exemplo para demonstra√ß√£o."""
    sample_dir = Path(__file__).parent.parent.parent / "sample_data" / "documents"
    documentos = []

    for file_path in sample_dir.glob("*.txt"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                conteudo = f.read()
                documentos.append(Document(
                    page_content=conteudo,
                    metadata={"fonte": file_path.name}
                ))
        except Exception as e:
            print(f"   Aviso: N√£o foi poss√≠vel carregar {file_path}: {e}")

    for file_path in sample_dir.glob("*.md"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                conteudo = f.read()
                documentos.append(Document(
                    page_content=conteudo,
                    metadata={"fonte": file_path.name}
                ))
        except Exception as e:
            print(f"   Aviso: N√£o foi poss√≠vel carregar {file_path}: {e}")

    return documentos


def dividir_documentos(documentos: list[Document], tamanho_chunk: int = 500, sobreposicao: int = 100) -> list[Document]:
    """Divide documentos em chunks."""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=tamanho_chunk,
        chunk_overlap=sobreposicao,
        separators=["\n\n", "\n", ". ", " ", ""]
    )

    chunks = []
    for doc in documentos:
        doc_chunks = text_splitter.split_documents([doc])
        for i, chunk in enumerate(doc_chunks):
            chunk.metadata["indice_chunk"] = i
        chunks.extend(doc_chunks)

    return chunks


class RetrieverBM25:
    """Retriever baseado em palavras-chave BM25."""

    def __init__(self, documentos: list[Document]):
        """Inicializa retriever BM25 com documentos."""
        if not BM25_DISPONIVEL:
            raise ImportError("rank-bm25 √© necess√°rio. Instale com: pip install rank-bm25")

        self.documentos = documentos
        # Tokeniza documentos para BM25
        self.docs_tokenizados = [doc.page_content.lower().split() for doc in documentos]
        self.bm25 = BM25Okapi(self.docs_tokenizados)

    def recuperar(self, consulta: str, k: int = 4) -> list[tuple[Document, float]]:
        """Recupera top-k documentos para consulta."""
        consulta_tokenizada = consulta.lower().split()
        scores = self.bm25.get_scores(consulta_tokenizada)

        # Obt√©m √≠ndices top-k
        indices_top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]

        resultados = []
        for idx in indices_top:
            resultados.append((self.documentos[idx], scores[idx]))

        return resultados


class RetrieverVetor:
    """Retriever sem√¢ntico baseado em vetores."""

    def __init__(self, documentos: list[Document], nome_colecao: str = "busca_hibrida"):
        """Inicializa retriever de vetores com documentos."""
        if not CHROMA_DISPONIVEL:
            raise ImportError("chromadb √© necess√°rio. Instale com: pip install chromadb")

        self.embeddings = get_embeddings()
        self.vectorstore = Chroma.from_documents(
            documents=documentos,
            embedding=self.embeddings,
            collection_name=nome_colecao
        )

    def recuperar(self, consulta: str, k: int = 4) -> list[tuple[Document, float]]:
        """Recupera top-k documentos com scores de similaridade."""
        resultados = self.vectorstore.similarity_search_with_score(consulta, k=k)
        # Nota: Chroma retorna dist√¢ncia, menor √© melhor. Converte para similaridade.
        return [(doc, 1 / (1 + score)) for doc, score in resultados]


def fusao_rank_reciproco(
    lista_resultados: list[list[tuple[Document, float]]],
    pesos: list[float] = None,
    k: int = 60
) -> list[tuple[Document, float]]:
    """
    Combina resultados de m√∫ltiplos retrievers usando Reciprocal Rank Fusion.

    Score RRF = soma(peso_i / (k + rank_i)) para cada retriever

    Args:
        lista_resultados: Lista de resultados de cada retriever
        pesos: Pesos para cada retriever (padr√£o: pesos iguais)
        k: Par√¢metro RRF (tipicamente 60)

    Returns:
        Resultados combinados e reordenados
    """
    if pesos is None:
        pesos = [1.0] * len(lista_resultados)

    # Normaliza pesos
    peso_total = sum(pesos)
    pesos = [w / peso_total for w in pesos]

    # Calcula scores RRF
    scores_docs = {}

    for idx_retriever, resultados in enumerate(lista_resultados):
        peso = pesos[idx_retriever]

        for rank, (doc, _) in enumerate(resultados, start=1):
            # Usa conte√∫do do documento como chave (simplificado)
            chave_doc = doc.page_content[:100]

            if chave_doc not in scores_docs:
                scores_docs[chave_doc] = {"doc": doc, "score": 0.0}

            # F√≥rmula RRF
            scores_docs[chave_doc]["score"] += peso / (k + rank)

    # Ordena por score combinado
    resultados_ordenados = sorted(
        scores_docs.values(),
        key=lambda x: x["score"],
        reverse=True
    )

    return [(item["doc"], item["score"]) for item in resultados_ordenados]


class RetrieverHibrido:
    """Combina retrievers BM25 e de Vetores."""

    def __init__(
        self,
        documentos: list[Document],
        peso_bm25: float = 0.4,
        peso_vetor: float = 0.6,
        nome_colecao: str = "busca_hibrida"
    ):
        """
        Inicializa retriever h√≠brido.

        Args:
            documentos: Documentos para indexar
            peso_bm25: Peso para resultados BM25
            peso_vetor: Peso para resultados de vetores
        """
        self.documentos = documentos
        self.peso_bm25 = peso_bm25
        self.peso_vetor = peso_vetor

        print("   Inicializando retriever BM25...")
        self.retriever_bm25 = RetrieverBM25(documentos)

        print("   Inicializando retriever de Vetores...")
        self.retriever_vetor = RetrieverVetor(documentos, nome_colecao)

    def recuperar(self, consulta: str, k: int = 4, k_inicial: int = 10) -> list[tuple[Document, float]]:
        """
        Recupera documentos usando busca h√≠brida.

        Args:
            consulta: Consulta de busca
            k: N√∫mero de resultados finais
            k_inicial: N√∫mero de candidatos de cada retriever

        Returns:
            Resultados combinados com scores RRF
        """
        # Obt√©m resultados de ambos retrievers
        resultados_bm25 = self.retriever_bm25.recuperar(consulta, k=k_inicial)
        resultados_vetor = self.retriever_vetor.recuperar(consulta, k=k_inicial)

        # Combina usando RRF
        combinados = fusao_rank_reciproco(
            [resultados_bm25, resultados_vetor],
            pesos=[self.peso_bm25, self.peso_vetor]
        )

        return combinados[:k]


def comparar_metodos_recuperacao(chunks: list[Document], consulta: str, k: int = 3):
    """Compara m√©todos de recupera√ß√£o BM25, Vetor e H√≠brido."""

    print(f"\n   Consulta: '{consulta}'")
    print("   " + "=" * 50)

    # Somente BM25
    print("\n   üìö Resultados BM25 (Palavras-chave):")
    print("   " + "-" * 30)

    retriever_bm25 = RetrieverBM25(chunks)
    resultados_bm25 = retriever_bm25.recuperar(consulta, k=k)

    for i, (doc, score) in enumerate(resultados_bm25, 1):
        preview = doc.page_content[:100].replace('\n', ' ')
        print(f"   {i}. Score: {score:.4f}")
        print(f"      Fonte: {doc.metadata.get('fonte', doc.metadata.get('source', 'Desconhecida'))}")
        print(f"      Preview: {preview}...")
        print()

    # Somente Vetor
    print("\n   üîÆ Resultados Vetor (Sem√¢ntico):")
    print("   " + "-" * 30)

    retriever_vetor = RetrieverVetor(chunks, nome_colecao="comparar_vetor")
    resultados_vetor = retriever_vetor.recuperar(consulta, k=k)

    for i, (doc, score) in enumerate(resultados_vetor, 1):
        preview = doc.page_content[:100].replace('\n', ' ')
        print(f"   {i}. Score: {score:.4f}")
        print(f"      Fonte: {doc.metadata.get('fonte', doc.metadata.get('source', 'Desconhecida'))}")
        print(f"      Preview: {preview}...")
        print()

    # H√≠brido
    print("\n   üîÑ Resultados H√≠bridos (BM25 + Vetor):")
    print("   " + "-" * 30)

    combinados = fusao_rank_reciproco(
        [resultados_bm25, resultados_vetor],
        pesos=[0.4, 0.6]
    )

    for i, (doc, score) in enumerate(combinados[:k], 1):
        preview = doc.page_content[:100].replace('\n', ' ')
        print(f"   {i}. Score RRF: {score:.4f}")
        print(f"      Fonte: {doc.metadata.get('fonte', doc.metadata.get('source', 'Desconhecida'))}")
        print(f"      Preview: {preview}...")
        print()


def gerar_resposta_com_contexto(consulta: str, documentos: list[tuple[Document, float]]) -> str:
    """Gera resposta usando contexto recuperado."""

    llm = get_llm(temperature=0.3)

    contexto = "\n\n---\n\n".join([
        f"[Fonte: {doc.metadata.get('fonte', doc.metadata.get('source', 'Desconhecida'))}]\n{doc.page_content}"
        for doc, _ in documentos
    ])

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um assistente √∫til que responde perguntas baseado no contexto fornecido.
Use APENAS as informa√ß√µes do contexto para responder. Se a resposta n√£o estiver no contexto, diga isso.
Seja conciso mas completo."""),
        ("user", """Contexto:
{contexto}

Pergunta: {pergunta}

Resposta:""")
    ])

    chain = prompt | llm
    response = chain.invoke({"contexto": contexto, "pergunta": consulta})

    input_tokens, output_tokens = extract_tokens_from_response(response)
    token_tracker.add(input_tokens, output_tokens)
    print_token_usage(input_tokens, output_tokens, "Gera√ß√£o de Resposta")

    return response.content


def demonstrar_vantagem_hibrida():
    """Mostra casos onde busca h√≠brida supera m√©todos individuais."""

    print("\n   Demonstrando Vantagens da Busca H√≠brida...")
    print("   " + "=" * 50)

    # Cria documentos sint√©ticos que destacam diferen√ßas
    documentos = [
        Document(
            page_content="A linguagem de programa√ß√£o Python foi criada por Guido van Rossum. Ela enfatiza legibilidade de c√≥digo e usa indenta√ß√£o significativa.",
            metadata={"fonte": "visao_geral_python.txt"}
        ),
        Document(
            page_content="Algoritmos de machine learning podem ser implementados em Python usando bibliotecas como scikit-learn, TensorFlow e PyTorch.",
            metadata={"fonte": "ferramentas_ml.txt"}
        ),
        Document(
            page_content="Uma p√≠ton √© uma grande cobra encontrada em regi√µes tropicais. Esses r√©pteis s√£o constritores, significando que apertam suas presas.",
            metadata={"fonte": "animais.txt"}
        ),
        Document(
            page_content="Desenvolvimento web com frameworks Django e Flask torna Python uma excelente escolha para construir aplica√ß√µes escal√°veis.",
            metadata={"fonte": "dev_web.txt"}
        ),
        Document(
            page_content="Linguagens de programa√ß√£o como Java, C++ e Python s√£o amplamente usadas em desenvolvimento de software.",
            metadata={"fonte": "linguagens.txt"}
        ),
    ]

    # Consulta que se beneficia da abordagem h√≠brida
    consulta = "Python programa√ß√£o desenvolvimento web"

    print(f"\n   Consulta: '{consulta}'")
    print("\n   Esta consulta se beneficia da busca h√≠brida porque:")
    print("   - BM25 captura correspond√™ncias exatas da palavra 'Python'")
    print("   - Busca vetorial entende rela√ß√£o sem√¢ntica com dev web")
    print("   - Abordagem combinada filtra o documento sobre cobra")

    comparar_metodos_recuperacao(documentos, consulta, k=3)


def main():
    print("=" * 60)
    print("BUSCA H√çBRIDA (BM25 + Vetor)")
    print("=" * 60)

    if not BM25_DISPONIVEL:
        print("\nErro: rank-bm25 √© necess√°rio para esta demonstra√ß√£o.")
        print("Instale com: pip install rank-bm25")
        return

    if not CHROMA_DISPONIVEL:
        print("\nErro: chromadb √© necess√°rio para esta demonstra√ß√£o.")
        print("Instale com: pip install chromadb")
        return

    token_tracker.reset()

    # Carrega e prepara documentos
    print("\nüìö CARREGANDO E PREPARANDO DOCUMENTOS")
    print("-" * 40)

    documentos = carregar_documentos_exemplo()

    if not documentos:
        print("   Nenhum documento encontrado. Usando documentos de exemplo.")
        documentos = [
            Document(
                page_content="Machine learning √© um subconjunto de intelig√™ncia artificial que permite sistemas aprenderem com dados.",
                metadata={"fonte": "exemplo.txt"}
            )
        ]

    print(f"   Carregados {len(documentos)} documentos")

    chunks = dividir_documentos(documentos, tamanho_chunk=400, sobreposicao=80)
    print(f"   Criados {len(chunks)} chunks")

    # Inicializa retriever h√≠brido
    print("\nüîß INICIALIZANDO RETRIEVER H√çBRIDO")
    print("-" * 40)

    retriever_hibrido = RetrieverHibrido(
        chunks,
        peso_bm25=0.4,
        peso_vetor=0.6,
        nome_colecao="demo_hibrido"
    )

    # Consultas de demonstra√ß√£o
    consultas = [
        "O que √© machine learning?",
        "redes neurais deep learning",
        "Como construir aplica√ß√µes de IA?"
    ]

    print("\n\n‚ùì CONSULTAS DE BUSCA H√çBRIDA")
    print("=" * 60)

    for consulta in consultas:
        print(f"\nüìå Consulta: {consulta}")
        print("-" * 40)

        resultados = retriever_hibrido.recuperar(consulta, k=3)

        print("\n   Documentos Recuperados:")
        for i, (doc, score) in enumerate(resultados, 1):
            preview = doc.page_content[:100].replace('\n', ' ')
            print(f"   {i}. Score RRF: {score:.4f}")
            print(f"      Fonte: {doc.metadata.get('fonte', doc.metadata.get('source', 'Desconhecida'))}")
            print(f"      Preview: {preview}...")
            print()

        print("\n   Gerando resposta...")
        resposta = gerar_resposta_com_contexto(consulta, resultados)
        print(f"\n   Resposta: {resposta}")

    # Compara m√©todos
    print("\n\nüìä COMPARANDO M√âTODOS DE RECUPERA√á√ÉO")
    print("=" * 60)

    comparar_metodos_recuperacao(
        chunks,
        "aplica√ß√µes de intelig√™ncia artificial",
        k=3
    )

    # Demonstra vantagem h√≠brida
    print("\n\nüéØ VANTAGEM DA BUSCA H√çBRIDA")
    print("=" * 60)

    demonstrar_vantagem_hibrida()

    # Guia de ajuste de pesos
    print("\n\nüí° GUIA DE AJUSTE DE PESOS")
    print("-" * 40)
    print("""
   Ajuste os pesos baseado no seu caso de uso:

   | Caso de Uso                | Peso BM25 | Peso Vetor |
   |----------------------------|-----------|------------|
   | Docs t√©cnicos (precisos)   | 0.6       | 0.4        |
   | Conhecimento geral         | 0.3       | 0.7        |
   | Busca de c√≥digo            | 0.5       | 0.5        |
   | FAQ/Suporte                | 0.4       | 0.6        |

   Dicas:
   - Maior peso BM25 para correspond√™ncia exata de termos (IDs, c√≥digos, nomes)
   - Maior peso Vetor para consultas conceituais/sem√¢nticas
   - Comece com 0.4/0.6 e ajuste baseado nos resultados
    """)

    print_total_usage(token_tracker, "TOTAL - Busca H√≠brida")

    print("\nFim da demonstra√ß√£o de Busca H√≠brida")
    print("=" * 60)


if __name__ == "__main__":
    main()
